Most interesting are Go timings because this is fastest impl.


-----------

After Go 1.8 -> 1.9 switch:

BenchmarkOpenQS-4    1000000	      1464 ns/op	     640 B/op	       9 allocs/op
BenchmarkNbs-4     	30000000	        55.9 ns/op	       0 B/op	       0 allocs/op
BenchmarkAstar-4   	    5000	    346681 ns/op	   60139 B/op	     205 allocs/op

-----------

After moving Astar to ext. lib & switching to Node interface:

BenchmarkOpenQS-4  	 1000000	      1672 ns/op	     704 B/op	      13 allocs/op
BenchmarkNbs-4     	30000000	        56.1 ns/op	       0 B/op	       0 allocs/op
BenchmarkAstar-4   	    5000	    346037 ns/op	   58984 B/op	     211 allocs/op

------------

After Go 1.7 -> 1.8 switch:

BenchmarkOpenqOps-4   	 1000000	      1674 ns/op	     704 B/op	      13 allocs/op
BenchmarkNbs-4        	20000000	        96.1 ns/op	      32 B/op	       1 allocs/op
BenchmarkAstar-4      	    5000	    343625 ns/op	   58956 B/op	     212 allocs/op

------------

After using embedded index in OpenQS and some optimizations:

BenchmarkOpenqOps-4      1000000          1718 ns/op         704 B/op         13 allocs/op
BenchmarkNbs-4          20000000           100 ns/op          32 B/op          1 allocs/op
BenchmarkAstar-4            5000        357060 ns/op       57184 B/op        212 allocs/op

------------

After going to 64bits on the same hardware (ray laptop),
there is a small speedup:

BenchmarkOpenqOps-4   	 1000000	      2004 ns/op	     704 B/op	      16 allocs/op
BenchmarkNbs-4        	20000000	        96.5 ns/op	      32 B/op	       1 allocs/op
BenchmarkAstar-4      	    5000	    375232 ns/op	   55397 B/op	     250 allocs/op

Previous record was 385Âµs/op after switching to sector uint constants
(commit ffcf062).

Some of previous experiments are noted in the commit logs.

-----------
Timings below are old. Some of the code has been changed
(like python version which uses 'fancy' heap now).
Keeping just for the record.

enioar 1,1 to 20.7:

  mostly-linear scanning on node deletion from heap:
    py: 15-30 ms (gc triggered?)        moon
    pl: 65-85 ms                        moon

    py: 5 ms                            silver

  fancy heap structures:
    erl: 16-19 ms                       moon

    erl: 3.5 ms                         silver
    ex:  2.7 ms                         silver

    erl: 1.8 ms                         xcite1
    ex:  1.4 ms                         -//-

    What is interesting for xcite1 is that the timings are
    the same whether it's rescaled for 1/8vcpu, 1/4 or 1vcpu.
    Looks like bigger cpu usage is handled in bursts.
    Very good outcome.


  simpler but still special heap structures:
    rkt: 20-30 ms                       moon

For ex (Elixir) see eastar repository.
